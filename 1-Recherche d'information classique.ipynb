{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/Zbrlaa/RI_TP1/blob/main/1-Recherche%20d'information%20classique.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ugX7FayQ90_A"
   },
   "source": [
    "# Partie 1. - Recherche d'Information classique\n",
    "\n",
    "Dans cette partie, nous allons mettre en œuvre des principes et modèles classiques de Recherche d'Information. Le jeu de données est une collection de livres au format texte (.txt) de Henry Rider Haggard. Jetez un œil à ces documents dans le dossier _data_.\n",
    "\n",
    "En sortie de ce module, vous serez capable de :\n",
    "\n",
    "- Construire un index inversé ;\n",
    "- Effectuer des requêtes simples selon le modèle booléen :\n",
    "- Calculer la pondération des termes selon la méthode TF-IDF ;\n",
    "- Mettre en œuvre le modèle vectoriel de recherche d'information et y appliquer des requêtes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tw1BGZgY-tvZ"
   },
   "source": [
    "### Import des bibliothèques logicielles et configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les lignes suivantes permettent d'instancier un objet de la classe `IRSystem` représentant notre moteur de recherche et de charger les données en RAM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pas sur Google Colab, ces commandes ne seront pas exécutées.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Vérifie si le code est exécuté sur Google Colab\n",
    "if 'COLAB_GPU' in os.environ:\n",
    "    # Commandes à exécuter uniquement sur Google Colab\n",
    "    !git clone https://github.com/vincentmartin/tp-information-retrieval-with-llm-student-version.git\n",
    "    %cd tp-information-retrieval-with-llm-student-version\n",
    "else:\n",
    "    # Commandes à exécuter si ce n'est pas sur Google Colab\n",
    "    print(\"Pas sur Google Colab, ces commandes ne seront pas exécutées.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chargement des données\n",
    "\n",
    "Les lignes ci-dessous permettent de charger les données qui sont un ensemble de 60 livres au format texte (.txt) d'[Henry Rider Haggard](https://fr.wikipedia.org/wiki/Henry_Rider_Haggard).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "ZNWPECSs9wgH"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/etudiants/spelerin797/Documents/RI_TP1/classic_ir/IRSystem.py:35: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  title_pattern = re.compile('(.*) \\d+\\.txt')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading in documents...\n",
      "Stemming Documents...\n",
      "A Winter Pilgrimage (1901) 0600121.txt\n",
      "    Doc 1 of 60: A Winter Pilgrimage (1901)\n",
      "A Yellow God an Idol of Africa 2857.txt\n",
      "    Doc 2 of 60: A Yellow God an Idol of Africa\n",
      "Allan Quatermain 711.txt\n",
      "    Doc 3 of 60: Allan Quatermain\n",
      "Allan and the Holy Flower 5174.txt\n",
      "    Doc 4 of 60: Allan and the Holy Flower\n",
      "Allan and the Ice Gods (1927) 0200201.txt\n",
      "    Doc 5 of 60: Allan and the Ice Gods (1927)\n",
      "Allan's Wife 2727.txt\n",
      "    Doc 6 of 60: Allan's Wife\n",
      "Ayesha, the Return of She 5228.txt\n",
      "    Doc 7 of 60: Ayesha, the Return of She\n",
      "Beatrice 3096.txt\n",
      "    Doc 8 of 60: Beatrice\n",
      "Benita, an African romance 2761.txt\n",
      "    Doc 9 of 60: Benita, an African romance\n",
      "Black Heart and White Heart 2842.txt\n",
      "    Doc 10 of 60: Black Heart and White Heart\n",
      "Cetywayo and his White Neighbours 0.txt\n",
      "    Doc 11 of 60: Cetywayo and his White Neighbours\n",
      "Child of Storm 1711.txt\n",
      "    Doc 12 of 60: Child of Storm\n",
      "Cleopatra 2769.txt\n",
      "    Doc 13 of 60: Cleopatra\n",
      "Colonel Quaritch, V.C. A Tale of Country Life 11882.txt\n",
      "    Doc 14 of 60: Colonel Quaritch, V.C. A Tale of Country Life\n",
      "Dawn 10892.txt\n",
      "    Doc 15 of 60: Dawn\n",
      "Doctor Therne 5764.txt\n",
      "    Doc 16 of 60: Doctor Therne\n",
      "Elissa 2855.txt\n",
      "    Doc 17 of 60: Elissa\n",
      "Eric Brighteyes 2721.txt\n",
      "    Doc 18 of 60: Eric Brighteyes\n",
      "Fair Margaret 9780.txt\n",
      "    Doc 19 of 60: Fair Margaret\n",
      "Finished 1724.txt\n",
      "    Doc 20 of 60: Finished\n",
      "Heu-Heu (1924) 0200191.txt\n",
      "    Doc 21 of 60: Heu-Heu (1924)\n",
      "Hunter Quatermain's Story 2728.txt\n",
      "    Doc 22 of 60: Hunter Quatermain's Story\n",
      "Jess 5898.txt\n",
      "    Doc 23 of 60: Jess\n",
      "King Solomon's Mines 2166.txt\n",
      "    Doc 24 of 60: King Solomon's Mines\n",
      "Long Odds 1918.txt\n",
      "    Doc 25 of 60: Long Odds\n",
      "Love Eternal 3709.txt\n",
      "    Doc 26 of 60: Love Eternal\n",
      "Lysbeth, a Tale of the Dutch 5754.txt\n",
      "    Doc 27 of 60: Lysbeth, a Tale of the Dutch\n",
      "Maiwa's Revenge 2713.txt\n",
      "    Doc 28 of 60: Maiwa's Revenge\n",
      "Marie An Episode in The Life of the late Allan Quatermain 1690.txt\n",
      "    Doc 29 of 60: Marie An Episode in The Life of the late Allan Quatermain\n",
      "Montezuma's Daughter 1848.txt\n",
      "    Doc 30 of 60: Montezuma's Daughter\n",
      "Moon of Israel 2856.txt\n",
      "    Doc 31 of 60: Moon of Israel\n",
      "Morning Star 2722.txt\n",
      "    Doc 32 of 60: Morning Star\n",
      "Mr. Meeson's Will 11913.txt\n",
      "    Doc 33 of 60: Mr. Meeson's Will\n",
      "Nada the Lily 1207.txt\n",
      "    Doc 34 of 60: Nada the Lily\n",
      "Pearl-Maiden 5175.txt\n",
      "    Doc 35 of 60: Pearl-Maiden\n",
      "Queen Sheba's Ring 2602.txt\n",
      "    Doc 36 of 60: Queen Sheba's Ring\n",
      "Queen of the Dawn (1925) 0200381.txt\n",
      "    Doc 37 of 60: Queen of the Dawn (1925)\n",
      "Red Eve 3094.txt\n",
      "    Doc 38 of 60: Red Eve\n",
      "Regeneration 13434.txt\n",
      "    Doc 39 of 60: Regeneration\n",
      "She 3155.txt\n",
      "    Doc 40 of 60: She\n",
      "She and Allan 5745.txt\n",
      "    Doc 41 of 60: She and Allan\n",
      "Smith and the Pharaohs, and other Tales 6073.txt\n",
      "    Doc 42 of 60: Smith and the Pharaohs, and other Tales\n",
      "Stella Fregelius 6051.txt\n",
      "    Doc 43 of 60: Stella Fregelius\n",
      "Stories by English Authors Africa (Selected by Scribners) 1980.txt\n",
      "    Doc 44 of 60: Stories by English Authors Africa (Selected by Scribners)\n",
      "Swallow a tale of the great trek 4074.txt\n",
      "    Doc 45 of 60: Swallow a tale of the great trek\n",
      "The Ancient Allan 5746.txt\n",
      "    Doc 46 of 60: The Ancient Allan\n",
      "The Brethren 2762.txt\n",
      "    Doc 47 of 60: The Brethren\n",
      "The Ghost Kings 8184.txt\n",
      "    Doc 48 of 60: The Ghost Kings\n",
      "The Ivory Child 2841.txt\n",
      "    Doc 49 of 60: The Ivory Child\n",
      "The Lady of Blossholme 3813.txt\n",
      "    Doc 50 of 60: The Lady of Blossholme\n",
      "The Mahatma and the Hare 2764.txt\n",
      "    Doc 51 of 60: The Mahatma and the Hare\n",
      "The People of the Mist 6769.txt\n",
      "    Doc 52 of 60: The People of the Mist\n",
      "The Tale of Three Lions 2729.txt\n",
      "    Doc 53 of 60: The Tale of Three Lions\n",
      "The Virgin of the Sun 3153.txt\n",
      "    Doc 54 of 60: The Virgin of the Sun\n",
      "The Wanderer's Necklace 3097.txt\n",
      "    Doc 55 of 60: The Wanderer's Necklace\n",
      "The Witch's Head (1884) 0500791.txt\n",
      "    Doc 56 of 60: The Witch's Head (1884)\n",
      "The Wizard 2893.txt\n",
      "    Doc 57 of 60: The Wizard\n",
      "The World's Desire 2763.txt\n",
      "    Doc 58 of 60: The World's Desire\n",
      "When the World Shook 0.txt\n",
      "    Doc 59 of 60: When the World Shook\n",
      "Wisdom's Daughter (1923) 0200181.txt\n",
      "    Doc 60 of 60: Wisdom's Daughter (1923)\n"
     ]
    }
   ],
   "source": [
    "from classic_ir.IRSystem import *\n",
    "\n",
    "# !rm -rf ./data/RiderHaggard/stemmed\n",
    "ir_system = IRSystem()\n",
    "ir_system.read_data('./data/RiderHaggard') # chargement des données et prétraitement des documents (stemming)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercice 1. - Construction de l'index inversé\n",
    "\n",
    "Ce premier exercice a pour objectif de construire l'index inversé non positionnel. L'attribut `self.inverted_index` est un tableau associatif qui associe une liste d'entiers (docIDs) à un mot (word).\n",
    " \n",
    "Documentation ici https://docs.python.org/3/library/collections.html#collections.defaultdict. \n",
    "\n",
    "Exercice : modifier la fonction `index` pour calculer l'index inversé. \n",
    "\n",
    "Le résultat ci-dessous indique que vous avez réussi.\n",
    "```\n",
    "===== Running tests =====\n",
    "Inverted Index Test\n",
    "    Score: 3 Feedback: 5/5 Correct. Accuracy: 1.000000\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['_IRSystem__read_raw_data', '_IRSystem__read_stemmed_data', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', 'alphanum', 'boolean_retrieve', 'compute_tfidf', 'docs', 'get_posting', 'get_posting_unstemmed', 'get_tfidf', 'get_tfidf_unstemmed', 'get_uniq_words', 'index', 'inverted_index', 'p', 'process_query', 'query_rank', 'query_retrieve', 'rank_retrieve', 'read_data', 'tf', 'titles', 'vocab']\n"
     ]
    }
   ],
   "source": [
    "print(dir(ir_system))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexing...\n",
      "===== Running tests =====\n",
      "Inverted Index Test\n",
      "    Score: 3 Feedback: 5/5 Correct. Accuracy: 1.000000\n"
     ]
    }
   ],
   "source": [
    "# Exercice 1. Indexation\n",
    "\n",
    "def index(self):\n",
    "\t\"\"\"\n",
    "\tConstruit l'index inversé et le stocke dans self.inverted_index.\n",
    "\n",
    "\tDans le code ci-dessous, seul le dictionnaire des tokens est construit. Les postings lists sont vides.\n",
    "\t\"\"\"\n",
    "\t\n",
    "\tprint(\"Indexing...\")\n",
    "\tself.tf = defaultdict(Counter) # tf est un dictionnaire qui à un document associe un Counter de mots.\n",
    "\tinverted_index = defaultdict(list) # inverted_index est un dictionnaire qui à un mot associe une liste de documents. \n",
    "\n",
    "\tfor doc_id, doc in enumerate(self.docs):\n",
    "\t\tfor w in doc :\n",
    "\t\t\tself.tf[doc_id][w] += 1\n",
    "\n",
    "\t\t\tif doc_id not in inverted_index[w]:\n",
    "\t\t\t\tinverted_index[w].append(doc_id)\n",
    "\n",
    "\tself.inverted_index = inverted_index\n",
    "\n",
    "# Ne pas modifier les lignes ci-dessous\n",
    "IRSystem.index = index\n",
    "ir_system.index()\n",
    "run_tests(ir_system, part=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercice 2. - Recherche booléenne\n",
    "\n",
    "Ce deuxième exercice a pour objectif d'implémenter la recherche booléenne. La requête `query` est une liste de mots _lemmatisés_ et l'algorithme doit rechercher les documents qui contiennent TOUS ces mots. \n",
    "\n",
    "\n",
    "Exercice : modifier la fonction `boolean_retrieve` pour implémenter la recherche booléenne.\n",
    "\n",
    "\n",
    "Le résultat ci-dessous indique que vous avez réussi.\n",
    "```\n",
    "===== Running tests =====\n",
    "Boolean Retrieval Test\n",
    "    Score: 3 Feedback: 5/5 Correct. Accuracy: 1.000000\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Running tests =====\n",
      "Boolean Retrieval Test\n",
      "    Score: 3 Feedback: 5/5 Correct. Accuracy: 1.000000\n"
     ]
    }
   ],
   "source": [
    "# Exercice 2. Recherche booléenne\n",
    "def boolean_retrieve(self, query):\n",
    "\t\"\"\"\n",
    "\tA partir d'une requête sous la forme d'une liste de mots *lemmatisés*,\n",
    "\tretourne la liste des documents dans lesquels *tous* ces mots apparaissent (ie une requête AND).\n",
    "\tRetourne une liste vide si la requête ne retourne aucun document.\n",
    "\n",
    "\tDans le code ci-dessous, tous les documents répondent.\n",
    "\t\"\"\"\n",
    "\t\n",
    "\tdocs = [i for i in range(len(self.docs))]\n",
    "\tfor w in query :\n",
    "\t\tdocs = list(set(docs) & set(self.get_posting(w)))\n",
    "\treturn docs\n",
    "\n",
    "# Ne pas modifier les lignes ci-dessous\n",
    "IRSystem.boolean_retrieve = boolean_retrieve\n",
    "run_tests(ir_system, part=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercice 3. - Calcul des poids TF-IDF des termes dans les documents\n",
    "\n",
    "Dans ce troisième exercice, l'objectif est de pré-calculer les poids TF-IDF pour chaque terme dans chaque document. Pour ce faire, appliquer la formule vue en cours. Utiliser le logarithme en base 10.\n",
    "\n",
    "\n",
    "Exercice : modifier la fonction `boolean_retrieve` pour implémenter la recherche booléenne.\n",
    "\n",
    "Le résultat ci-dessous indique que vous avez réussi.\n",
    "```\n",
    "Calculating tf-idf...\n",
    "===== Running tests =====\n",
    "TF-IDF Test\n",
    "    Score: 3 Feedback: 5/5 Correct. Accuracy: 1.000000\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating tf-idf...\n",
      "===== Running tests =====\n",
      "TF-IDF Test\n",
      "    Score: 3 Feedback: 5/5 Correct. Accuracy: 1.000000\n"
     ]
    }
   ],
   "source": [
    "# Exercice 3. calcul des scores tf-idf\n",
    "from math import log10\n",
    "\n",
    "def compute_tfidf(self):\n",
    "\t\"\"\"\n",
    "\tCalcule les scores tf-idf pour tous les mots de tous les documents et les stocke dans self.tfidf.\n",
    "\n",
    "\tDans le code ci-dessous, les scores tf-idf sont tous nuls.\n",
    "\t\"\"\"\n",
    "\tprint(\"Calculating tf-idf...\")\n",
    "\t\n",
    "\tself.tfidf = defaultdict(Counter)\n",
    "\tN = len(self.docs)  # N = nombre de documents\n",
    "\n",
    "\tfor word in self.vocab:\n",
    "\t\tfor i in range(N):\n",
    "\t\t\ttf = self.tf[i][word]\n",
    "\t\t\ttry:\n",
    "\t\t\t\tif(tf > 0) :\n",
    "\t\t\t\t\tdf = len(self.get_posting(word))\n",
    "\t\t\t\t\tself.tfidf[i][word] = (1+log10(tf)) * log10(N/df)\n",
    "\t\t\t\telse :\n",
    "\t\t\t\t\tself.tfidf[i][word] = 0.\n",
    "\t\t\texcept e:\n",
    "\t\t\t\tprint(f\"Erreur {e}\")\n",
    "\n",
    "# Ne pas modifier les lignes ci-dessous\n",
    "IRSystem.compute_tfidf = compute_tfidf\n",
    "ir_system.compute_tfidf()\n",
    "run_tests(ir_system, part=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercice 4. - Calcul de la similarité cosinus.\n",
    "\n",
    "Dans ce troisième exercice, l'objectif est de calculer la similarité cosinus entre le vecteur requête `query` et chaque vecteur document. Pour ce faire, appliquer la formule vue en cours en considérant les éléments suivants :\n",
    "- Ne considérer que la mesure TF pour calculer le poids des termes de la requête (on n'utilise pas IDF).\n",
    "- Utiliser le logarithme en base 10. \n",
    "\n",
    "Exercice : modifier la fonction `rank_retrieve` pour implémenter la recherche booléenne.\n",
    "\n",
    "Le résultat ci-dessous indique que vous avez réussi.\n",
    "```\n",
    "===== Running tests =====\n",
    "Cosine Similarity Test\n",
    "    Score: 3 Feedback: 5/5 Correct. Accuracy: 1.000000\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Running tests =====\n",
      "Cosine Similarity Test\n",
      "[(56, 0.010676611271744088), (25, 0.008463116269726562), (49, 0.008462987843582521), (37, 0.00839586658084902), (18, 0.008360056776471416), (54, 0.008320124278304216), (5, 0.008316020650549037), (41, 0.008312726995818018), (29, 0.00785209214713161), (44, 0.007814399700034913)]\n",
      "\n",
      "[(59, 0.05041279333939136), (31, 0.042933912797404966), (16, 0.04245722537237054), (36, 0.0391023868431653), (3, 0.03250369701658961), (45, 0.03200276000633705), (40, 0.028353460953342218), (1, 0.02298825032652949), (6, 0.022750210842425178), (48, 0.022439179053556423)]\n",
      "\n",
      "[(15, 0.03405789447552078), (41, 0.02218901367816242), (39, 0.021800770675665816), (13, 0.016669193743447684), (16, 0.010152619001197564), (52, 0.009352842834467906), (27, 0.00861473088344378), (50, 0.008208957726149083), (29, 0.008035449433972445), (5, 0.00746212911745865)]\n",
      "\n",
      "[(24, 0.015298081869538089), (21, 0.014226522006871), (45, 0.01402257841496572), (56, 0.013840806806046085), (5, 0.013141186012001212), (1, 0.012625486696803643), (48, 0.012498273714045294), (20, 0.012457449764659869), (16, 0.012282892363857142), (2, 0.012196143140743609)]\n",
      "\n",
      "[(21, 0.035182936915852864), (9, 0.027699818304687557), (5, 0.0202680826202428), (52, 0.020034479924314754), (47, 0.018942423003715667), (44, 0.01814214732393999), (27, 0.018121080290215197), (19, 0.017391667372811948), (33, 0.01676017058071806), (28, 0.0165815931013749)]\n",
      "\n",
      "    Score: 3 Feedback: 5/5 Correct. Accuracy: 1.000000\n"
     ]
    }
   ],
   "source": [
    "# Exercice 4. Similarité cosinus\n",
    "from math import log10, sqrt\n",
    "\n",
    "def rank_retrieve(self, query):\n",
    "\t\"\"\"\n",
    "\tA partir d'une requête (une liste de mots), retourne une liste de documents (classés par docID) et de scores pour la requête en appliquant la simalirité cosinus.\n",
    "\n",
    "\tDans l'exemple ci-dessous. C'est la mesure de Jaccard qui est utilisée.\n",
    "\t\"\"\"\n",
    "\tscores = [0.0 for _ in range(len(self.docs))]\n",
    "\n",
    "\tquery_set = set(query)\n",
    "\t\n",
    "\tquery_tfidf = {}\n",
    "\tfor w in query_set :\n",
    "\t\tquery_tfidf[w] = 1+log10(query.count(w))\n",
    "\t\n",
    "\tfor doc_id, doc in enumerate(self.docs):\n",
    "\t\tqd = sum(query_tfidf[w] * self.tfidf[doc_id][w] for w in query_set)\n",
    "\t\td2 = sum(v * v for v in self.tfidf[doc_id].values())\n",
    "\t\t\t\n",
    "\t\tscores[doc_id] = qd / sqrt(d2) if d2 > 0 else 0.0\n",
    "\t\t\n",
    "\t# Tri des scores\n",
    "\tranking = [idx for idx, sim in sorted(enumerate(scores), key=lambda pair: pair[1], reverse=True)]\n",
    "\tresults = []\n",
    "\n",
    "\tfor i in range(10):\n",
    "\t\tresults.append((ranking[i], scores[ranking[i]]))\n",
    "\n",
    "\tprint(f\"{results}\\n\")\n",
    "\treturn results\n",
    "\n",
    "# Ne pas modifier les lignes ci-dessous\n",
    "IRSystem.rank_retrieve = rank_retrieve\n",
    "run_tests(ir_system, part=3)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNKktqd75RwDFlI5Cdrd/bs",
   "gpuType": "T4",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
